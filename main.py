import os
import sys
import asyncio
import threading
import subprocess
import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext, simpledialog
from tkinter import ttk
import docx
import edge_tts
from openai import OpenAI
import imageio_ffmpeg
import re  # æ–°å¢ï¼šå¼•å…¥æ­£åˆ™åº“ï¼Œç”¨äºå¤„ç†éšå½¢åŒéŸ³å­—

# é»˜è®¤é…ç½®
DEFAULT_DEEPSEEK_URL = "https://api.deepseek.com"

# --- è¯­éŸ³è§’è‰²æ˜ å°„è¡¨ ---
VOICE_MAP = {
    "æ™“æ™“ (å¥³å£° - æ´»æ³¼/é»˜è®¤)": "zh-CN-XiaoxiaoNeural",
    "äº‘å¸Œ (ç”·å£° - æ²‰ç¨³/å½±è§†)": "zh-CN-YunxiNeural",
    "äº‘å¥ (ç”·å£° - ä½“è‚²/è§£è¯´)": "zh-CN-YunjianNeural",
    "æ™“ä¼Š (å¥³å£° - å¯çˆ±/å„¿ç«¥)": "zh-CN-XiaoyiNeural",
    "äº‘æ‰¬ (ç”·å£° - æ–°é—»/æ’­éŸ³)": "zh-CN-YunyangNeural",
    "è¾½å®å°åŒ— (æ–¹è¨€ - ä¸œåŒ—è¯)": "zh-CN-Liaoning-XiaobeiNeural",
    "é™•è¥¿å°å¦® (æ–¹è¨€ - é™•è¥¿è¯)": "zh-CN-Shaanxi-XiaoniNeural",
    "é¦™æ¸¯æ™“ä½³ (æ–¹è¨€ - ç²¤è¯­)": "zh-HK-HiuGaaiNeural",
    "å°æ¹¾æ™“è‡» (æ–¹è¨€ - å°æ¹¾è…”)": "zh-TW-HsiaoChenNeural",
    "è‹±è¯­ (å¥³å£° - Aria)": "en-US-AriaNeural",
    "è‹±è¯­ (ç”·å£° - Christopher)": "en-US-ChristopherNeural"
}

class TTSApp:
    def __init__(self, root):
        self.root = root
        self.root.title("DeepSeek æ™ºèƒ½è¯­éŸ³åˆæˆåŠ©æ‰‹ - ä½œè€…: Yu JinQuan")
        
        window_width = 950
        window_height = 700
        self.center_window(window_width, window_height)
        self.root.minsize(800, 500)
        
        self.is_playing = False
        self.is_generating = False 
        self.temp_audio_file = "temp_preview.mp3"
        self.loop = asyncio.new_event_loop()
        
        self.selected_voice_key = tk.StringVar(value="æ™“æ™“ (å¥³å£° - æ´»æ³¼/é»˜è®¤)")
        
        threading.Thread(target=self.start_loop, daemon=True).start()
        self.create_ui()

    def center_window(self, width, height):
        screen_width = self.root.winfo_screenwidth()
        screen_height = self.root.winfo_screenheight()
        x = (screen_width // 2) - (width // 2)
        y = (screen_height // 2) - (height // 2)
        self.root.geometry(f'{width}x{height}+{x}+{y}')

    def start_loop(self):
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()

    def create_ui(self):
        # 1. é¡¶éƒ¨æ“ä½œåŒº
        frame_top = tk.LabelFrame(self.root, text="æ–‡ä»¶ä¸ç¼–è¾‘", padx=10, pady=5)
        frame_top.pack(side=tk.TOP, fill=tk.X, padx=10, pady=(10, 5))
        
        tk.Button(frame_top, text="ğŸ“‚ å¯¼å…¥æ–‡æœ¬/Word", command=self.import_file).pack(side=tk.LEFT, padx=5)
        tk.Button(frame_top, text="ğŸ—‘ï¸ æ¸…ç©ºå†…å®¹", command=self.clear_text, bg="#ffebee").pack(side=tk.LEFT, padx=5)
        
        tk.Frame(frame_top, width=20).pack(side=tk.LEFT) # å ä½
        tk.Label(frame_top, text="é€‰ä¸­å¤šéŸ³å­—åç‚¹å‡» ->", fg="gray").pack(side=tk.LEFT)
        tk.Button(frame_top, text="ğŸ“ ä¿®æ­£é€‰ä¸­å­—è¯»éŸ³", command=self.fix_pronunciation, bg="#fff3e0").pack(side=tk.LEFT, padx=5)

        # 2. åº•éƒ¨æ§åˆ¶åŒº (å€’åº)
        frame_status = tk.Frame(self.root, bd=1, relief=tk.SUNKEN, bg="#f0f0f0")
        frame_status.pack(side=tk.BOTTOM, fill=tk.X)
        self.status_label = tk.Label(frame_status, text="çŠ¶æ€: å°±ç»ª", anchor=tk.W, bg="#f0f0f0")
        self.status_label.pack(side=tk.LEFT, padx=5)
        tk.Label(frame_status, text="Author: Yu JinQuan", anchor=tk.E, bg="#f0f0f0", fg="#666").pack(side=tk.RIGHT, padx=10)

        frame_bottom = tk.LabelFrame(self.root, text="è¯­éŸ³æ§åˆ¶ä¸å¯¼å‡º", padx=10, pady=5)
        frame_bottom.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(5, 10))
        
        tk.Label(frame_bottom, text="é€‰æ‹©è¯­éŸ³:").pack(side=tk.LEFT, padx=(5, 0))
        voice_combo = ttk.Combobox(frame_bottom, textvariable=self.selected_voice_key, values=list(VOICE_MAP.keys()), state="readonly", width=25)
        voice_combo.pack(side=tk.LEFT, padx=5)

        tk.Frame(frame_bottom, width=2, bg="#ccc").pack(side=tk.LEFT, fill=tk.Y, padx=10)

        tk.Button(frame_bottom, text="â–¶ï¸ ç”Ÿæˆå¹¶æ’­æ”¾", command=self.play_audio, bg="#e8f5e9", width=12).pack(side=tk.LEFT, padx=5)
        tk.Button(frame_bottom, text="â¹ï¸ åœæ­¢", command=self.stop_audio, bg="#ffcdd2", width=8).pack(side=tk.LEFT, padx=5)
        
        tk.Frame(frame_bottom, width=2, bg="#ccc").pack(side=tk.LEFT, fill=tk.Y, padx=10)
        
        tk.Button(frame_bottom, text="ğŸ’¾ å¯¼å‡º MP3", command=lambda: self.export_audio("mp3")).pack(side=tk.LEFT, padx=5)
        tk.Button(frame_bottom, text="ğŸµ å¯¼å‡º WAV", command=lambda: self.export_audio("wav")).pack(side=tk.LEFT, padx=5)

        # 3. AI æ¶¦è‰²åŒº
        frame_ai = tk.LabelFrame(self.root, text="DeepSeek AI æ¶¦è‰²", padx=10, pady=5)
        frame_ai.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=5)
        tk.Label(frame_ai, text="æç¤º: å°†æ–‡æœ¬æ”¹å†™ä¸ºæ›´è‡ªç„¶çš„å£è¯­é£æ ¼").pack(side=tk.LEFT)
        tk.Button(frame_ai, text="âœ¨ å¼€å§‹æ™ºèƒ½æ¶¦è‰²", command=self.run_deepseek_polish, bg="#e3f2fd", fg="#0d47a1").pack(side=tk.RIGHT, padx=5)

        # 4. ä¸­é—´æ–‡æœ¬åŒº
        self.text_area = scrolledtext.ScrolledText(self.root, font=("Microsoft YaHei", 12), wrap=tk.WORD)
        self.text_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=10, pady=5)

    def update_status(self, text):
        self.status_label.config(text=f"çŠ¶æ€: {text}")
        self.root.update_idletasks()

    # --- æ ¸å¿ƒåŠŸèƒ½ï¼šåŒéŸ³å­—ä¿®æ­£è¯»éŸ³ ---
    def fix_pronunciation(self):
        try:
            selection = self.text_area.get(tk.SEL_FIRST, tk.SEL_LAST)
        except tk.TclError:
            messagebox.showwarning("æç¤º", "è¯·å…ˆåœ¨æ–‡æœ¬æ¡†ä¸­é€‰ä¸­éœ€è¦ä¿®æ­£çš„æ±‰å­—ï¼ˆæ¯æ¬¡é€‰ä¸€ä¸ªå­—ï¼‰ï¼")
            return

        if not selection.strip() or len(selection.strip()) > 1:
            messagebox.showwarning("æç¤º", "æ¯æ¬¡è¯·åªé€‰ä¸­ä¸€ä¸ªæ±‰å­—ï¼")
            return

        # æç¤ºè¾“å…¥åŒéŸ³å­—ï¼Œè€Œä¸æ˜¯æ‹¼éŸ³
        hint = f"è¯·è¾“å…¥ [{selection}] çš„ã€åŒéŸ³å­—ã€‘\nä¾‹å¦‚ï¼šå¦‚æœä½ å¸Œæœ›æŠŠâ€œè¡Œâ€è¯»æˆâ€œèˆªâ€ï¼Œè¯·ç›´æ¥è¾“å…¥ï¼šèˆª"
        homophone = simpledialog.askstring("ä¿®æ­£è¯»éŸ³", hint)
        
        if homophone and len(homophone.strip()) > 0:
            homophone = homophone.strip()[0] # åªå–ç¬¬ä¸€ä¸ªå­—
            # æ’å…¥æ˜“è¯»çš„æ ‡è®°ï¼Œä¾‹å¦‚ï¼šè¡Œ[è¯»éŸ³:èˆª]
            marker = f"{selection}[è¯»éŸ³:{homophone}]"
            self.text_area.delete(tk.SEL_FIRST, tk.SEL_LAST)
            self.text_area.insert(tk.INSERT, marker)
            self.update_status(f"å·²ä¿®æ­£: '{selection}' å°†è¢«è¯»ä½œ '{homophone}'")

    # --- æ–‡ä»¶æ“ä½œ ---
    def import_file(self):
        file_path = filedialog.askopenfilename(filetypes=[("Text/Word", "*.txt *.docx")])
        if not file_path: return
        try:
            content = ""
            if file_path.lower().endswith(".txt"):
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
            elif file_path.lower().endswith(".docx"):
                doc = docx.Document(file_path)
                content = "\n".join([para.text for para in doc.paragraphs])
            self.text_area.delete("1.0", tk.END)
            self.text_area.insert(tk.END, content)
            self.update_status(f"å·²åŠ è½½: {os.path.basename(file_path)}")
        except Exception as e:
            messagebox.showerror("å¯¼å…¥å¤±è´¥", str(e))

    def clear_text(self):
        self.text_area.delete("1.0", tk.END)
        self.stop_audio()
        self.update_status("å†…å®¹å·²æ¸…ç©º")

    # --- DeepSeek ---
    def run_deepseek_polish(self):
        text = self.text_area.get("1.0", tk.END).strip()
        if not text:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¾“å…¥éœ€è¦æ¶¦è‰²çš„æ–‡æœ¬")
            return
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            api_key = simpledialog.askstring("API Key", "è¯·è¾“å…¥ DeepSeek API Key:", show="*")
            if not api_key: return
            os.environ["DEEPSEEK_API_KEY"] = api_key 

        threading.Thread(target=self._deepseek_thread, args=(text, api_key)).start()

    def _deepseek_thread(self, text, api_key):
        self.update_status("æ­£åœ¨è¿æ¥ DeepSeek AI...")
        try:
            client = OpenAI(api_key=api_key, base_url=DEFAULT_DEEPSEEK_URL)
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é…éŸ³æ–‡æ¡ˆæ¶¦è‰²ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¿®æ”¹ä¸ºé€‚åˆæœ—è¯»çš„å£è¯­åŒ–æ–‡æ¡ˆã€‚ç›´æ¥è¾“å‡ºç»“æœã€‚"},
                    {"role": "user", "content": text},
                ],
                stream=False
            )
            polished = response.choices[0].message.content
            self.root.after(0, lambda: self.text_area.delete("1.0", tk.END))
            self.root.after(0, lambda: self.text_area.insert(tk.END, polished))
            self.root.after(0, lambda: self.update_status("æ¶¦è‰²å®Œæˆ"))
            self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", "DeepSeek æ¶¦è‰²å·²å®Œæˆï¼"))
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("API é”™è¯¯", f"è¯·æ±‚å¤±è´¥: {str(e)}"))
            self.root.after(0, lambda: self.update_status("æ¶¦è‰²å¤±è´¥"))

    # --- è¯­éŸ³åˆæˆæ ¸å¿ƒ (æ­£åˆ™æ›¿æ¢) ---
    async def _generate_audio_task(self, text, output_file):
        selected_name = self.selected_voice_key.get()
        voice_id = VOICE_MAP.get(selected_name, "zh-CN-XiaoxiaoNeural")
        
        # === æ ¸å¿ƒä¿®æ”¹ï¼šéšå½¢æ›¿æ¢é­”æ³• ===
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œå°†æ–‡æœ¬ä¸­çš„ "è¡Œ[è¯»éŸ³:èˆª]" å·å·æ›¿æ¢ä¸º "èˆª"
        # \1 ä»£è¡¨åŸå­—ï¼Œ\2 ä»£è¡¨åŒéŸ³å­—ã€‚è¿™é‡Œç›´æ¥æå– \2 ä¼ ç»™è¯­éŸ³å¼•æ“
        processed_text = re.sub(r'(.)\[è¯»éŸ³:(.)\]', r'\2', text)
        
        communicate = edge_tts.Communicate(processed_text, voice_id)
        await communicate.save(output_file)

    def play_audio(self):
        text = self.text_area.get("1.0", tk.END).strip()
        if not text: return
        self.stop_audio()
        self.is_generating = True
        self.update_status(f"æ­£åœ¨åˆæˆ ({self.selected_voice_key.get()})...")
        
        def run_gen():
            try:
                future = asyncio.run_coroutine_threadsafe(
                    self._generate_audio_task(text, self.temp_audio_file), self.loop
                )
                future.result() 
                if not self.is_generating: return
                self.root.after(0, self._play_sound)
            except Exception as e:
                self.root.after(0, lambda: messagebox.showerror("åˆæˆé”™è¯¯", str(e)))
                self.root.after(0, lambda: self.update_status("åˆæˆå‡ºé”™"))

        threading.Thread(target=run_gen).start()

    def _play_sound(self):
        try:
            import pygame
            pygame.mixer.init()
            pygame.mixer.music.load(self.temp_audio_file)
            pygame.mixer.music.play()
            self.is_playing = True
            self.is_generating = False
            self.update_status("æ­£åœ¨æ’­æ”¾...")
        except Exception as e:
            messagebox.showerror("æ’­æ”¾é”™è¯¯", str(e))

    def stop_audio(self):
        self.is_generating = False 
        try:
            import pygame
            pygame.mixer.init()
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.stop()
                pygame.mixer.music.unload()
        except:
            pass
        self.is_playing = False
        self.update_status("å·²åœæ­¢")

    def export_audio(self, fmt):
        text = self.text_area.get("1.0", tk.END).strip()
        if not text: return

        ext = ".mp3" if fmt == "mp3" else ".wav"
        save_path = filedialog.asksaveasfilename(defaultextension=ext, filetypes=[(f"{fmt.upper()} File", f"*{ext}")])
        if not save_path: return

        self.update_status(f"æ­£åœ¨å¯¼å‡ºä¸º {fmt}...")

        def run_export():
            try:
                temp_mp3 = "temp_export.mp3"
                future = asyncio.run_coroutine_threadsafe(
                    self._generate_audio_task(text, temp_mp3), self.loop
                )
                future.result()

                if fmt == "mp3":
                    import shutil
                    shutil.move(temp_mp3, save_path)
                    
                elif fmt == "wav":
                    self.root.after(0, lambda: self.update_status("æ­£åœ¨è½¬æ¢æ ¼å¼ (FFmpeg)..."))
                    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()
                    cmd = [
                        ffmpeg_exe, "-y",
                        "-i", temp_mp3,
                        "-acodec", "pcm_s16le",
                        "-ar", "44100", 
                        "-ac", "2", 
                        save_path
                    ]
                    subprocess.check_call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    if os.path.exists(temp_mp3):
                        os.remove(temp_mp3)

                self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"å¯¼å‡ºæˆåŠŸï¼\nä¿å­˜è·¯å¾„: {save_path}"))
                self.root.after(0, lambda: self.update_status("å¯¼å‡ºå®Œæˆ"))
            except Exception as e:
                self.root.after(0, lambda: messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"é”™è¯¯è¯¦æƒ…:\n{str(e)}"))
                self.root.after(0, lambda: self.update_status("å¯¼å‡ºå¤±è´¥"))

        threading.Thread(target=run_export).start()

if __name__ == "__main__":
    root = tk.Tk()
    app = TTSApp(root)
    root.mainloop()
